
import com.sun.jna.Pointer;
import com.sun.jna.Structure;
import com.sun.jna.ptr.IntByReference;
import com.sun.jna.ptr.PointerByReference;
import com.sun.jna.ptr.ShortByReference;
import java.util.Arrays;
import java.util.List;
/**
 * <i>native declaration : /usr/include/libavcodec/avcodec.h:4208</i><br>
 * This file was autogenerated by <a href="http://jnaerator.googlecode.com/">JNAerator</a>,<br>
 * a tool written by <a href="http://ochafik.com/">Olivier Chafik</a> that <a href="http://code.google.com/p/jnaerator/wiki/CreditsAndLicense">uses a few opensource projects.</a>.<br>
 * For help, please visit <a href="http://nativelibs4java.googlecode.com/">NativeLibs4Java</a> , <a href="http://rococoa.dev.java.net/">Rococoa</a>, or <a href="http://jna.dev.java.net/">JNA</a>.
 */
public class AVFrame extends Structure {
	/**
	 * pointer to the picture/channel planes.<br>
	 * This might be different from the first allocated byte<br>
	 * - encoding: Set by user<br>
	 * - decoding: set by AVCodecContext.get_buffer()<br>
	 * C type : uint8_t*[4]
	 */
	public Pointer[] data = new Pointer[4];
	/**
	 * Size, in bytes, of the data for each picture/channel plane.<br>
	 * * For audio, only linesize[0] may be set. For planar audio, each channel<br>
	 * plane must be the same size.<br>
	 * * - encoding: Set by user (video only)<br>
	 * - decoding: set by AVCodecContext.get_buffer()<br>
	 * C type : int[4]
	 */
	public int[] linesize = new int[4];
	/**
	 * pointer to the first allocated byte of the picture. Can be used in get_buffer/release_buffer.<br>
	 * This isn't used by libavcodec unless the default get/release_buffer() is used.<br>
	 * - encoding:<br>
	 * - decoding:<br>
	 * C type : uint8_t*[4]
	 */
	public Pointer[] base = new Pointer[4];
	/**
	 * 1 -> keyframe, 0-> not<br>
	 * - encoding: Set by libavcodec.<br>
	 * - decoding: Set by libavcodec.
	 */
	public int key_frame;
	/**
	 * Picture type of the frame, see ?_TYPE below.<br>
	 * - encoding: Set by libavcodec. for coded_picture (and set by user for input).<br>
	 * - decoding: Set by libavcodec.<br>
	 * @see com.acuitus.wrapffmpeg.AvutilLibrary#AVPictureType<br>
	 * C type : AVPictureType
	 */
	public int pict_type;
	/**
	 * presentation timestamp in time_base units (time when frame should be shown to user)<br>
	 * If AV_NOPTS_VALUE then frame_rate = 1/time_base will be assumed.<br>
	 * - encoding: MUST be set by user.<br>
	 * - decoding: Set by libavcodec.
	 */
	public long pts;
	/**
	 * picture number in bitstream order<br>
	 * - encoding: set by<br>
	 * - decoding: Set by libavcodec.
	 */
	public int coded_picture_number;
	/**
	 * picture number in display order<br>
	 * - encoding: set by<br>
	 * - decoding: Set by libavcodec.
	 */
	public int display_picture_number;
	/**
	 * quality (between 1 (good) and FF_LAMBDA_MAX (bad))<br>
	 * - encoding: Set by libavcodec. for coded_picture (and set by user for input).<br>
	 * - decoding: Set by libavcodec.
	 */
	public int quality;
	/** @deprecated unused */
	public int age;
	/**
	 * is this picture used as reference<br>
	 * The values for this are the same as the MpegEncContext.picture_structure<br>
	 * variable, that is 1->top field, 2->bottom field, 3->frame/both fields.<br>
	 * Set to 4 for delayed, non-reference frames.<br>
	 * - encoding: unused<br>
	 * - decoding: Set by libavcodec. (before get_buffer() call)).
	 */
	public int reference;
	/**
	 * QP table<br>
	 * - encoding: unused<br>
	 * - decoding: Set by libavcodec.<br>
	 * C type : int8_t*
	 */
	public Pointer qscale_table;
	/**
	 * QP store stride<br>
	 * - encoding: unused<br>
	 * - decoding: Set by libavcodec.
	 */
	public int qstride;
	/**
	 * mbskip_table[mb]>=1 if MB didn't change<br>
	 * stride= mb_width = (width+15)>>4<br>
	 * - encoding: unused<br>
	 * - decoding: Set by libavcodec.<br>
	 * C type : uint8_t*
	 */
	public Pointer mbskip_table;
	/**
	 * motion vector table<br>
	 * @code<br>
	 * example:<br>
	 * int mv_sample_log2= 4 - motion_subsample_log2;<br>
	 * int mb_width= (width+15)>>4;<br>
	 * int mv_stride= (mb_width << mv_sample_log2) + 1;<br>
	 * motion_val[direction][x + y*mv_stride][0->mv_x, 1->mv_y];<br>
	 * @endcode<br>
	 * - encoding: Set by user.<br>
	 * - decoding: Set by libavcodec.<br>
	 * C type : int16_t[2]*[2]
	 */
	public Pointer[] motion_val = new Pointer[2];
	/**
	 * macroblock type table<br>
	 * mb_type_base + mb_width + 2<br>
	 * - encoding: Set by user.<br>
	 * - decoding: Set by libavcodec.<br>
	 * C type : uint32_t*
	 */
	public IntByReference mb_type;
	/**
	 * log2 of the size of the block which a single vector in motion_val represents:<br>
	 * (4->16x16, 3->8x8, 2-> 4x4, 1-> 2x2)<br>
	 * - encoding: unused<br>
	 * - decoding: Set by libavcodec.
	 */
	public byte motion_subsample_log2;
	/**
	 * for some private data of the user<br>
	 * - encoding: unused<br>
	 * - decoding: Set by user.<br>
	 * C type : void*
	 */
	public Pointer opaque;
	/**
	 * error<br>
	 * - encoding: Set by libavcodec. if flags&CODEC_FLAG_PSNR.<br>
	 * - decoding: unused<br>
	 * C type : uint64_t[4]
	 */
	public long[] error = new long[4];
	/**
	 * type of the buffer (to keep track of who has to deallocate data[*])<br>
	 * - encoding: Set by the one who allocates it.<br>
	 * - decoding: Set by the one who allocates it.<br>
	 * Note: User allocated (direct rendering) & internal buffers cannot coexist currently.
	 */
	public int type;
	/**
	 * When decoding, this signals how much the picture must be delayed.<br>
	 * extra_delay = repeat_pict / (2*fps)<br>
	 * - encoding: unused<br>
	 * - decoding: Set by libavcodec.
	 */
	public int repeat_pict;
	public int qscale_type;
	/**
	 * The content of the picture is interlaced.<br>
	 * - encoding: Set by user.<br>
	 * - decoding: Set by libavcodec. (default 0)
	 */
	public int interlaced_frame;
	/**
	 * If the content is interlaced, is top field displayed first.<br>
	 * - encoding: Set by user.<br>
	 * - decoding: Set by libavcodec.
	 */
	public int top_field_first;
	/**
	 * Pan scan.<br>
	 * - encoding: Set by user.<br>
	 * - decoding: Set by libavcodec.<br>
	 * C type : AVPanScan*
	 */
	public AVPanScan.ByReference pan_scan;
	/**
	 * Tell user application that palette has changed from previous frame.<br>
	 * - encoding: ??? (no palette-enabled encoder yet)<br>
	 * - decoding: Set by libavcodec. (default 0).
	 */
	public int palette_has_changed;
	/**
	 * codec suggestion on buffer type if != 0<br>
	 * - encoding: unused<br>
	 * - decoding: Set by libavcodec. (before get_buffer() call)).
	 */
	public int buffer_hints;
	/**
	 * DCT coefficients<br>
	 * - encoding: unused<br>
	 * - decoding: Set by libavcodec.<br>
	 * C type : short*
	 */
	public ShortByReference dct_coeff;
	/**
	 * motion reference frame index<br>
	 * the order in which these are stored can depend on the codec.<br>
	 * - encoding: Set by user.<br>
	 * - decoding: Set by libavcodec.<br>
	 * C type : int8_t*[2]
	 */
	public Pointer[] ref_index = new Pointer[2];
	/**
	 * reordered opaque 64bit (generally an integer or a double precision float<br>
	 * PTS but can be anything).<br>
	 * The user sets AVCodecContext.reordered_opaque to represent the input at<br>
	 * that time,<br>
	 * the decoder reorders values as needed and sets AVFrame.reordered_opaque<br>
	 * to exactly one of the values provided by the user through AVCodecContext.reordered_opaque<br>
	 * @deprecated in favor of pkt_pts<br>
	 * - encoding: unused<br>
	 * - decoding: Read by user.
	 */
	public long reordered_opaque;
	/**
	 * hardware accelerator private data (Libav-allocated)<br>
	 * - encoding: unused<br>
	 * - decoding: Set by libavcodec<br>
	 * C type : void*
	 */
	public Pointer hwaccel_picture_private;
	/**
	 * reordered pts from the last AVPacket that has been input into the decoder<br>
	 * - encoding: unused<br>
	 * - decoding: Read by user.
	 */
	public long pkt_pts;
	/**
	 * dts from the last AVPacket that has been input into the decoder<br>
	 * - encoding: unused<br>
	 * - decoding: Read by user.
	 */
	public long pkt_dts;
	/**
	 * the AVCodecContext which ff_thread_get_buffer() was last called on<br>
	 * - encoding: Set by libavcodec.<br>
	 * - decoding: Set by libavcodec.<br>
	 * C type : AVCodecContext*
	 */
	public AVCodecContext.ByReference owner;
	/**
	 * used by multithreading to store frame-specific info<br>
	 * - encoding: Set by libavcodec.<br>
	 * - decoding: Set by libavcodec.<br>
	 * C type : void*
	 */
	public Pointer thread_opaque;
	/**
	 * number of audio samples (per channel) described by this frame<br>
	 * - encoding: unused<br>
	 * - decoding: Set by libavcodec
	 */
	public int nb_samples;
	/**
	 * pointers to the data planes/channels.<br>
	 * * For video, this should simply point to data[].<br>
	 * * For planar audio, each channel has a separate data pointer, and<br>
	 * linesize[0] contains the size of each channel buffer.<br>
	 * For packed audio, there is just one data pointer, and linesize[0]<br>
	 * contains the total size of the buffer for all channels.<br>
	 * * Note: Both data and extended_data will always be set by get_buffer(),<br>
	 * but for planar audio with more channels that can fit in data,<br>
	 * extended_data must be used by the decoder in order to access all<br>
	 * channels.<br>
	 * * encoding: unused<br>
	 * decoding: set by AVCodecContext.get_buffer()<br>
	 * C type : uint8_t**
	 */
	public PointerByReference extended_data;
	/**
	 * sample aspect ratio for the video frame, 0/1 if unknown\\unspecified<br>
	 * - encoding: unused<br>
	 * - decoding: Read by user.<br>
	 * C type : AVRational
	 */
	public AVRational sample_aspect_ratio;
	/**
	 * width and height of the video frame<br>
	 * - encoding: unused<br>
	 * - decoding: Read by user.
	 */
	public int width;
	/**
	 * width and height of the video frame<br>
	 * - encoding: unused<br>
	 * - decoding: Read by user.
	 */
	public int height;
	/**
	 * format of the frame, -1 if unknown or unset<br>
	 * Values correspond to enum PixelFormat for video frames,<br>
	 * enum AVSampleFormat for audio)<br>
	 * - encoding: unused<br>
	 * - decoding: Read by user.
	 */
	public int format;
	public AVFrame() {
		super();
	}
	protected List<? > getFieldOrder() {
		return Arrays.asList("data", "linesize", "base", "key_frame", "pict_type", "pts", "coded_picture_number", "display_picture_number", "quality", "age", "reference", "qscale_table", "qstride", "mbskip_table", "motion_val", "mb_type", "motion_subsample_log2", "opaque", "error", "type", "repeat_pict", "qscale_type", "interlaced_frame", "top_field_first", "pan_scan", "palette_has_changed", "buffer_hints", "dct_coeff", "ref_index", "reordered_opaque", "hwaccel_picture_private", "pkt_pts", "pkt_dts", "owner", "thread_opaque", "nb_samples", "extended_data", "sample_aspect_ratio", "width", "height", "format");
	}
	public static class ByReference extends AVFrame implements Structure.ByReference {
		
	};
	public static class ByValue extends AVFrame implements Structure.ByValue {
		
	};
}
