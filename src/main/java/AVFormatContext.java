
import com.sun.jna.Pointer;
import com.sun.jna.Structure;
import com.sun.jna.ptr.PointerByReference;
import java.util.Arrays;
import java.util.List;
/**
 * <i>native declaration : /usr/include/libavformat/avformat.h:8134</i><br>
 * This file was autogenerated by <a href="http://jnaerator.googlecode.com/">JNAerator</a>,<br>
 * a tool written by <a href="http://ochafik.com/">Olivier Chafik</a> that <a href="http://code.google.com/p/jnaerator/wiki/CreditsAndLicense">uses a few opensource projects.</a>.<br>
 * For help, please visit <a href="http://nativelibs4java.googlecode.com/">NativeLibs4Java</a> , <a href="http://rococoa.dev.java.net/">Rococoa</a>, or <a href="http://jna.dev.java.net/">JNA</a>.
 */
public class AVFormatContext extends Structure {
	/**
	 * A class for logging and AVOptions. Set by avformat_alloc_context().<br>
	 * Exports (de)muxer private options if they exist.<br>
	 * C type : const AVClass*
	 */
	public AVClass.ByReference av_class;
	/**
	 * Can only be iformat or oformat, not both at the same time.<br>
	 * * decoding: set by avformat_open_input().<br>
	 * encoding: set by the user.<br>
	 * C type : AVInputFormat*
	 */
	public AVInputFormat.ByReference iformat;
	/** C type : AVOutputFormat* */
	public AVOutputFormat.ByReference oformat;
	/**
	 * Format private data. This is an AVOptions-enabled struct<br>
	 * if and only if iformat/oformat.priv_class is not NULL.<br>
	 * C type : void*
	 */
	public Pointer priv_data;
	/**
	 * I/O context.<br>
	 * * decoding: either set by the user before avformat_open_input() (then<br>
	 * the user must close it manually) or set by avformat_open_input().<br>
	 * encoding: set by the user.<br>
	 * * Do NOT set this field if AVFMT_NOFILE flag is set in<br>
	 * iformat/oformat.flags. In such a case, the (de)muxer will handle<br>
	 * I/O in some other way and this field will be NULL.<br>
	 * C type : AVIOContext*
	 */
	public AVIOContext.ByReference pb;
	/**
	 * A list of all streams in the file. New streams are created with<br>
	 * avformat_new_stream().<br>
	 * * decoding: streams are created by libavformat in avformat_open_input().<br>
	 * If AVFMTCTX_NOHEADER is set in ctx_flags, then new streams may also<br>
	 * appear in av_read_frame().<br>
	 * encoding: streams are created by the user before avformat_write_header().
	 */
	public int nb_streams;
	/** C type : AVStream** */
	public Pointer streams;
	/**
	 * < input or output filename<br>
	 * C type : char[1024]
	 */
	public byte[] filename = new byte[1024];
	/** @deprecated use 'creation_time' metadata tag instead */
	public long timestamp;
	/** < Format-specific flags, see AVFMTCTX_xx */
	public int ctx_flags;
	/**
	 * This buffer is only needed when packets were already buffered but<br>
	 * not decoded, for example to get the codec parameters in MPEG<br>
	 * streams.<br>
	 * C type : AVPacketList*
	 */
	public AVPacketList.ByReference packet_buffer;
	/**
	 * Decoding: position of the first frame of the component, in<br>
	 * AV_TIME_BASE fractional seconds. NEVER set this value directly:<br>
	 * It is deduced from the AVStream values.
	 */
	public long start_time;
	/**
	 * Decoding: duration of the stream, in AV_TIME_BASE fractional<br>
	 * seconds. Only set this value if you know none of the individual stream<br>
	 * durations and also do not set any of them. This is deduced from the<br>
	 * AVStream values if not set.
	 */
	public long duration;
	/** decoding: total file size, 0 if unknown */
	public long file_size;
	/**
	 * Decoding: total stream bitrate in bit/s, 0 if not<br>
	 * available. Never set it directly if the file_size and the<br>
	 * duration are known as Libav can compute it automatically.
	 */
	public int bit_rate;
	/**
	 * av_read_frame() support<br>
	 * C type : AVStream*
	 */
	public AVStream.ByReference cur_st;
	/**
	 * av_seek_frame() support<br>
	 * < offset of the first packet
	 */
	public long data_offset;
	/** use mpeg muxer private options instead */
	public int mux_rate;
	public int packet_size;
	public int preload;
	public int max_delay;
	/**
	 * number of times to loop output in formats that support it<br>
	 * * @deprecated use the 'loop' private option in the gif muxer.
	 */
	public int loop_output;
	public int flags;
	/** @deprecated, use the 'loop' img2 demuxer private option. */
	public int loop_input;
	/** decoding: size of data to probe; encoding: unused. */
	public int probesize;
	/**
	 * decoding: maximum time (in AV_TIME_BASE units) during which the input should<br>
	 * be analyzed in avformat_find_stream_info().
	 */
	public int max_analyze_duration;
	/** C type : const uint8_t* */
	public Pointer key;
	public int keylen;
	public int nb_programs;
	/** C type : AVProgram** */
	public Pointer programs;
	/**
	 * Forced video codec_id.<br>
	 * Demuxing: Set by user.<br>
	 * @see com.acuitus.wrapffmpeg.AvcodecLibrary#CodecID<br>
	 * C type : CodecID
	 */
	public int video_codec_id;
	/**
	 * Forced audio codec_id.<br>
	 * Demuxing: Set by user.<br>
	 * @see com.acuitus.wrapffmpeg.AvcodecLibrary#CodecID<br>
	 * C type : CodecID
	 */
	public int audio_codec_id;
	/**
	 * Forced subtitle codec_id.<br>
	 * Demuxing: Set by user.<br>
	 * @see com.acuitus.wrapffmpeg.AvcodecLibrary#CodecID<br>
	 * C type : CodecID
	 */
	public int subtitle_codec_id;
	/**
	 * Maximum amount of memory in bytes to use for the index of each stream.<br>
	 * If the index exceeds this size, entries will be discarded as<br>
	 * needed to maintain a smaller size. This can lead to slower or less<br>
	 * accurate seeking (depends on demuxer).<br>
	 * Demuxers for which a full in-memory index is mandatory will ignore<br>
	 * this.<br>
	 * muxing  : unused<br>
	 * demuxing: set by user
	 */
	public int max_index_size;
	/**
	 * Maximum amount of memory in bytes to use for buffering frames<br>
	 * obtained from realtime capture devices.
	 */
	public int max_picture_buffer;
	public int nb_chapters;
	/** C type : AVChapter** */
	public Pointer chapters;
	/** Flags to enable debugging. */
	public int debug;
	/**
	 * Raw packets from the demuxer, prior to parsing and decoding.<br>
	 * This buffer is used for buffering packets until the codec can<br>
	 * be identified, as parsing cannot be done without knowing the<br>
	 * codec.<br>
	 * C type : AVPacketList*
	 */
	public AVPacketList.ByReference raw_packet_buffer;
	/** C type : AVPacketList* */
	public AVPacketList.ByReference raw_packet_buffer_end;
	/** C type : AVPacketList* */
	public AVPacketList.ByReference packet_buffer_end;
	/** C type : AVDictionary* */
	public PointerByReference metadata;
	public int raw_packet_buffer_remaining_size;
	/**
	 * Start time of the stream in real world time, in microseconds<br>
	 * since the unix epoch (00:00 1st January 1970). That is, pts=0<br>
	 * in the stream was captured at this real world time.<br>
	 * - encoding: Set by user.<br>
	 * - decoding: Unused.
	 */
	public long start_time_realtime;
	/** decoding: number of frames used to probe fps */
	public int fps_probe_size;
	/**
	 * Error recognition; higher values will detect more errors but may<br>
	 * misdetect some more or less valid parts as errors.<br>
	 * - encoding: unused<br>
	 * - decoding: Set by user.
	 */
	public int error_recognition;
	/**
	 * Custom interrupt callbacks for the I/O layer.<br>
	 * * decoding: set by the user before avformat_open_input().<br>
	 * encoding: set by the user before avformat_write_header()<br>
	 * (mainly useful for AVFMT_NOFILE formats). The callback<br>
	 * should also be passed to avio_open2() if it's used to<br>
	 * open the file.<br>
	 * C type : AVIOInterruptCB
	 */
	public AVIOInterruptCB interrupt_callback;
	public AVFormatContext() {
		super();
	}
	protected List<? > getFieldOrder() {
		return Arrays.asList("av_class", "iformat", "oformat", "priv_data", "pb", "nb_streams", "streams", "filename", "timestamp", "ctx_flags", "packet_buffer", "start_time", "duration", "file_size", "bit_rate", "cur_st", "data_offset", "mux_rate", "packet_size", "preload", "max_delay", "loop_output", "flags", "loop_input", "probesize", "max_analyze_duration", "key", "keylen", "nb_programs", "programs", "video_codec_id", "audio_codec_id", "subtitle_codec_id", "max_index_size", "max_picture_buffer", "nb_chapters", "chapters", "debug", "raw_packet_buffer", "raw_packet_buffer_end", "packet_buffer_end", "metadata", "raw_packet_buffer_remaining_size", "start_time_realtime", "fps_probe_size", "error_recognition", "interrupt_callback");
	}
	public static class ByReference extends AVFormatContext implements Structure.ByReference {
		
	};
	public static class ByValue extends AVFormatContext implements Structure.ByValue {
		
	};
}
